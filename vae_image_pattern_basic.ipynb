{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-18T20:20:39.832203Z",
     "start_time": "2023-12-18T20:20:38.235986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8141, 1917)\n",
      "RGB\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pillow_heif import register_heif_opener\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "\n",
    "register_heif_opener()\n",
    "\n",
    "image = Image.open('data/IMG_1432.HEIC')\n",
    "\n",
    "print(image.size)\n",
    "print(image.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1917, 8141])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[224, 223, 223,  ..., 211, 212, 210],\n         [225, 223, 223,  ..., 211, 212, 210],\n         [224, 223, 224,  ..., 211, 212, 210],\n         ...,\n         [ 86,  92, 106,  ..., 153, 156, 155],\n         [105, 109, 103,  ..., 158, 160, 164],\n         [114, 121, 110,  ..., 168, 139, 123]],\n\n        [[233, 232, 232,  ..., 225, 226, 223],\n         [234, 232, 232,  ..., 225, 226, 223],\n         [233, 232, 233,  ..., 225, 226, 223],\n         ...,\n         [ 98, 104, 118,  ..., 159, 162, 160],\n         [117, 121, 115,  ..., 164, 166, 169],\n         [126, 133, 122,  ..., 173, 144, 129]],\n\n        [[240, 239, 239,  ..., 234, 235, 231],\n         [241, 239, 239,  ..., 234, 235, 231],\n         [240, 239, 240,  ..., 234, 235, 231],\n         ...,\n         [ 22,  28,  42,  ...,  99, 102, 104],\n         [ 41,  45,  39,  ..., 104, 106, 113],\n         [ 54,  61,  50,  ..., 117,  88,  81]]], device='mps:0',\n       dtype=torch.uint8)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'mps'\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    transforms.PILToTensor() \n",
    "])\n",
    "\n",
    "img_tensor = transform(image)\n",
    "\n",
    "print(img_tensor.shape)\n",
    "img_tensor.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T20:20:45.819186Z",
     "start_time": "2023-12-18T20:20:45.141561Z"
    }
   },
   "id": "5c423a108ba6e62d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "SLICES = 100\n",
    "\n",
    "# calculate slice width\n",
    "slice_width = img_tensor.size(2) // SLICES\n",
    "\n",
    "# slice the image width wise into 100 pieces. discard any remainder  \n",
    "slices = [img_tensor[:, :, i*slice_width:(i+1)*slice_width] for i in range(SLICES)]\n",
    "\n",
    "# flatten\n",
    "flat_slices = [img_slice.reshape(-1) for img_slice in slices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T20:21:11.409642Z",
     "start_time": "2023-12-18T20:21:11.389620Z"
    }
   },
   "id": "acd7d8e49bfbe5a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([465831])\n"
     ]
    }
   ],
   "source": [
    "print(flat_slices[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T20:21:12.684741Z",
     "start_time": "2023-12-18T20:21:12.681747Z"
    }
   },
   "id": "f88122034590470c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flat_slice_size = flat_slices[0].shape\n",
    "hidden_size = flat_slice_size // 2\n",
    "latent_size = hidden_size // 2\n",
    "        \n",
    "# encoder portion. will take our slices and (learn to) encode them into the latent space\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.input_layer = nn.Linear(flat_slice_size, hidden_size)\n",
    "        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.mean = nn.Linear(hidden_size, latent_size)\n",
    "        self.var = nn.Linear(hidden_size, latent_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.input_layer(x))\n",
    "        x = self.relu(self.hidden_layer(x))\n",
    "        mean = self.mean(x)\n",
    "        log_variance = self.var(x)\n",
    "        \n",
    "        return mean, log_variance\n",
    "\n",
    "# decoder portion. takes data that is normally distributed in the latent space\n",
    "# and decodes to the input space\n",
    "class Decoder(nn.Module):\n",
    "    def _init_(self):\n",
    "        self.latent_in = nn.Linear(latent_size, hidden_size)\n",
    "        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, flat_slice_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.latent_in(x))\n",
    "        x = self.relu(self.hidden_layer(x))\n",
    "        mean = self.mean(x)\n",
    "        log_variance = self.var(x)\n",
    "        \n",
    "        return mean, log_variance\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96cc18b0c9e75d6e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7a78d08ace061cca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
